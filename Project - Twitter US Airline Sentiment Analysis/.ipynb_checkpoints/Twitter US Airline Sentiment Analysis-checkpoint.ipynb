{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('0000000000002747_training_twitter_x_y_train.csv')\n",
    "testing_data = pd.read_csv('0000000000002747_test_twitter_x_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567900433542488064</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ColeyGirouard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir I am scheduled for the morning, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 20:16:29 -0800</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569989168903819264</td>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WalterFaddoul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir seeing your workers time in and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 14:36:22 -0800</td>\n",
       "      <td>Indianapolis, Indiana; USA</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>568089179520954368</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LocalKyle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Flew ORD to Miami and back and  had gr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18 08:46:29 -0800</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>568928195581513728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amccarthy19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir @dultch97 that's horse radish üò§üê¥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 16:20:26 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568594180014014464</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J_Okayy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united so our flight into ORD was delayed bec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 18:13:11 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment    airline airline_sentiment_gold  \\\n",
       "0  567900433542488064          negative  Southwest                    NaN   \n",
       "1  569989168903819264          positive  Southwest                    NaN   \n",
       "2  568089179520954368          positive     United                    NaN   \n",
       "3  568928195581513728          negative  Southwest                    NaN   \n",
       "4  568594180014014464          negative     United                    NaN   \n",
       "\n",
       "            name negativereason_gold  retweet_count  \\\n",
       "0  ColeyGirouard                 NaN              0   \n",
       "1  WalterFaddoul                 NaN              0   \n",
       "2      LocalKyle                 NaN              0   \n",
       "3    amccarthy19                 NaN              0   \n",
       "4        J_Okayy                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @SouthwestAir I am scheduled for the morning, ...         NaN   \n",
       "1  @SouthwestAir seeing your workers time in and ...         NaN   \n",
       "2  @united Flew ORD to Miami and back and  had gr...         NaN   \n",
       "3     @SouthwestAir @dultch97 that's horse radish üò§üê¥         NaN   \n",
       "4  @united so our flight into ORD was delayed bec...         NaN   \n",
       "\n",
       "               tweet_created              tweet_location  \\\n",
       "0  2015-02-17 20:16:29 -0800             Washington D.C.   \n",
       "1  2015-02-23 14:36:22 -0800  Indianapolis, Indiana; USA   \n",
       "2  2015-02-18 08:46:29 -0800                    Illinois   \n",
       "3  2015-02-20 16:20:26 -0800                         NaN   \n",
       "4  2015-02-19 18:13:11 -0800                         NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0      Atlantic Time (Canada)  \n",
       "1  Central Time (US & Canada)  \n",
       "2  Central Time (US & Canada)  \n",
       "3      Atlantic Time (Canada)  \n",
       "4  Eastern Time (US & Canada)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.098000e+04</td>\n",
       "      <td>10980</td>\n",
       "      <td>10980</td>\n",
       "      <td>31</td>\n",
       "      <td>10980</td>\n",
       "      <td>24</td>\n",
       "      <td>10980.000000</td>\n",
       "      <td>10980</td>\n",
       "      <td>776</td>\n",
       "      <td>10980</td>\n",
       "      <td>7430</td>\n",
       "      <td>7403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6438</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10851</td>\n",
       "      <td>632</td>\n",
       "      <td>10758</td>\n",
       "      <td>2658</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>negative</td>\n",
       "      <td>JetBlueNews</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@united thanks</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>2015-02-23 06:57:24 -0800</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6851</td>\n",
       "      <td>2928</td>\n",
       "      <td>24</td>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>131</td>\n",
       "      <td>3</td>\n",
       "      <td>125</td>\n",
       "      <td>2819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.692169e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.795438e+14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.675883e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.685584e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.694753e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.698902e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.703106e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tweet_id airline_sentiment airline airline_sentiment_gold  \\\n",
       "count   1.098000e+04             10980   10980                     31   \n",
       "unique           NaN                 3       6                      3   \n",
       "top              NaN          negative  United               negative   \n",
       "freq             NaN              6851    2928                     24   \n",
       "mean    5.692169e+17               NaN     NaN                    NaN   \n",
       "std     7.795438e+14               NaN     NaN                    NaN   \n",
       "min     5.675883e+17               NaN     NaN                    NaN   \n",
       "25%     5.685584e+17               NaN     NaN                    NaN   \n",
       "50%     5.694753e+17               NaN     NaN                    NaN   \n",
       "75%     5.698902e+17               NaN     NaN                    NaN   \n",
       "max     5.703106e+17               NaN     NaN                    NaN   \n",
       "\n",
       "               name     negativereason_gold  retweet_count            text  \\\n",
       "count         10980                      24   10980.000000           10980   \n",
       "unique         6438                      11            NaN           10851   \n",
       "top     JetBlueNews  Customer Service Issue            NaN  @united thanks   \n",
       "freq             43                       9            NaN               6   \n",
       "mean            NaN                     NaN       0.080965             NaN   \n",
       "std             NaN                     NaN       0.740303             NaN   \n",
       "min             NaN                     NaN       0.000000             NaN   \n",
       "25%             NaN                     NaN       0.000000             NaN   \n",
       "50%             NaN                     NaN       0.000000             NaN   \n",
       "75%             NaN                     NaN       0.000000             NaN   \n",
       "max             NaN                     NaN      44.000000             NaN   \n",
       "\n",
       "       tweet_coord              tweet_created tweet_location  \\\n",
       "count          776                      10980           7430   \n",
       "unique         632                      10758           2658   \n",
       "top     [0.0, 0.0]  2015-02-23 06:57:24 -0800   New York, NY   \n",
       "freq           131                          3            125   \n",
       "mean           NaN                        NaN            NaN   \n",
       "std            NaN                        NaN            NaN   \n",
       "min            NaN                        NaN            NaN   \n",
       "25%            NaN                        NaN            NaN   \n",
       "50%            NaN                        NaN            NaN   \n",
       "75%            NaN                        NaN            NaN   \n",
       "max            NaN                        NaN            NaN   \n",
       "\n",
       "                     user_timezone  \n",
       "count                         7403  \n",
       "unique                          78  \n",
       "top     Eastern Time (US & Canada)  \n",
       "freq                          2819  \n",
       "mean                           NaN  \n",
       "std                            NaN  \n",
       "min                            NaN  \n",
       "25%                            NaN  \n",
       "50%                            NaN  \n",
       "75%                            NaN  \n",
       "max                            NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = training_data[\"text\"].values\n",
    "sentiments = training_data[\"airline_sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10980\n",
      "10980\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets))\n",
    "print(len(sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents = []\n",
    "for i in range(len(tweets)):\n",
    "    train_documents.append((word_tokenize(tweets[i]),sentiments[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['@', 'SouthwestAir', 'I', 'am', 'scheduled', 'for', 'the', 'morning', ',', '2', 'days', 'after', 'the', 'fact', ',', 'yes..not', 'sure', 'why', 'my', 'evening', 'flight', 'was', 'the', 'only', 'one', 'Cancelled', 'Flightled'], 'negative')\n"
     ]
    }
   ],
   "source": [
    "print(train_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "stops.update(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(words):\n",
    "    output_words = []\n",
    "    for w in words:\n",
    "        if w.lower() not in stops:\n",
    "            pos = pos_tag([w])\n",
    "            clean_word = lemmatizer.lemmatize(w, pos = get_simple_pos(pos[0][1]))\n",
    "            output_words.append(clean_word.lower())\n",
    "    return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents = [(clean_tweet(tweet), sentiment) for tweet, sentiment in train_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['southwestair', 'schedule', 'morning', '2', 'day', 'fact', 'yes..not', 'sure', 'even', 'flight', 'one', 'cancelled', 'flightled'], 'negative')\n"
     ]
    }
   ],
   "source": [
    "print(train_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = [sentiment for tweet, sentiment in train_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_documents = [\" \".join(tweet) for tweet, sentiment in train_documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>569682010270101504</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zsalim03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir In car gng to DFW. Pulled over 1h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 18:15:50 -0800</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569608307184242688</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sa_craig</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir after all, the plane didn‚Äôt land ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 13:22:57 -0800</td>\n",
       "      <td>College Station, TX</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>567879304593408001</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DanaChristos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>@SouthwestAir can't believe how many paying cu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 18:52:31 -0800</td>\n",
       "      <td>CT</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>569757651539660801</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rossj987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways I can legitimately say that I would...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 23:16:24 -0800</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>569900705852608513</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tranpham18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir still no response from AA. great ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 08:44:51 -0800</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id     airline airline_sentiment_gold          name  \\\n",
       "0  569682010270101504    American                    NaN      zsalim03   \n",
       "1  569608307184242688    American                    NaN      sa_craig   \n",
       "2  567879304593408001   Southwest                    NaN  DanaChristos   \n",
       "3  569757651539660801  US Airways                    NaN      rossj987   \n",
       "4  569900705852608513    American                    NaN    tranpham18   \n",
       "\n",
       "  negativereason_gold  retweet_count  \\\n",
       "0                 NaN              0   \n",
       "1                 NaN              0   \n",
       "2                 NaN              1   \n",
       "3                 NaN              0   \n",
       "4                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @AmericanAir In car gng to DFW. Pulled over 1h...         NaN   \n",
       "1  @AmericanAir after all, the plane didn‚Äôt land ...         NaN   \n",
       "2  @SouthwestAir can't believe how many paying cu...         NaN   \n",
       "3  @USAirways I can legitimately say that I would...         NaN   \n",
       "4  @AmericanAir still no response from AA. great ...         NaN   \n",
       "\n",
       "               tweet_created       tweet_location               user_timezone  \n",
       "0  2015-02-22 18:15:50 -0800                Texas  Central Time (US & Canada)  \n",
       "1  2015-02-22 13:22:57 -0800  College Station, TX  Central Time (US & Canada)  \n",
       "2  2015-02-17 18:52:31 -0800                   CT  Eastern Time (US & Canada)  \n",
       "3  2015-02-22 23:16:24 -0800     Washington, D.C.  Eastern Time (US & Canada)  \n",
       "4  2015-02-23 08:44:51 -0800        New York City  Eastern Time (US & Canada)  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.660000e+03</td>\n",
       "      <td>3660</td>\n",
       "      <td>9</td>\n",
       "      <td>3660</td>\n",
       "      <td>8</td>\n",
       "      <td>3660.000000</td>\n",
       "      <td>3660</td>\n",
       "      <td>243</td>\n",
       "      <td>3660</td>\n",
       "      <td>2477</td>\n",
       "      <td>2417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2805</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3650</td>\n",
       "      <td>209</td>\n",
       "      <td>3635</td>\n",
       "      <td>1258</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>United</td>\n",
       "      <td>negative</td>\n",
       "      <td>JetBlueNews</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@AmericanAir I purchased Main Cabin XT for f-1...</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>2015-02-23 15:25:46 -0800</td>\n",
       "      <td>USA</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>894</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.692226e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.087705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.779030e+14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.675924e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.685633e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.694842e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.698927e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.703083e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tweet_id airline airline_sentiment_gold         name  \\\n",
       "count   3.660000e+03    3660                      9         3660   \n",
       "unique           NaN       6                      2         2805   \n",
       "top              NaN  United               negative  JetBlueNews   \n",
       "freq             NaN     894                      8           20   \n",
       "mean    5.692226e+17     NaN                    NaN          NaN   \n",
       "std     7.779030e+14     NaN                    NaN          NaN   \n",
       "min     5.675924e+17     NaN                    NaN          NaN   \n",
       "25%     5.685633e+17     NaN                    NaN          NaN   \n",
       "50%     5.694842e+17     NaN                    NaN          NaN   \n",
       "75%     5.698927e+17     NaN                    NaN          NaN   \n",
       "max     5.703083e+17     NaN                    NaN          NaN   \n",
       "\n",
       "           negativereason_gold  retweet_count  \\\n",
       "count                        8    3660.000000   \n",
       "unique                       6            NaN   \n",
       "top     Customer Service Issue            NaN   \n",
       "freq                         3            NaN   \n",
       "mean                       NaN       0.087705   \n",
       "std                        NaN       0.762048   \n",
       "min                        NaN       0.000000   \n",
       "25%                        NaN       0.000000   \n",
       "50%                        NaN       0.000000   \n",
       "75%                        NaN       0.000000   \n",
       "max                        NaN      32.000000   \n",
       "\n",
       "                                                     text tweet_coord  \\\n",
       "count                                                3660         243   \n",
       "unique                                               3650         209   \n",
       "top     @AmericanAir I purchased Main Cabin XT for f-1...  [0.0, 0.0]   \n",
       "freq                                                    2          33   \n",
       "mean                                                  NaN         NaN   \n",
       "std                                                   NaN         NaN   \n",
       "min                                                   NaN         NaN   \n",
       "25%                                                   NaN         NaN   \n",
       "50%                                                   NaN         NaN   \n",
       "75%                                                   NaN         NaN   \n",
       "max                                                   NaN         NaN   \n",
       "\n",
       "                    tweet_created tweet_location               user_timezone  \n",
       "count                        3660           2477                        2417  \n",
       "unique                       3635           1258                          59  \n",
       "top     2015-02-23 15:25:46 -0800            USA  Eastern Time (US & Canada)  \n",
       "freq                            3             43                         925  \n",
       "mean                          NaN            NaN                         NaN  \n",
       "std                           NaN            NaN                         NaN  \n",
       "min                           NaN            NaN                         NaN  \n",
       "25%                           NaN            NaN                         NaN  \n",
       "50%                           NaN            NaN                         NaN  \n",
       "75%                           NaN            NaN                         NaN  \n",
       "max                           NaN            NaN                         NaN  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = testing_data[\"text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3660\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents = []\n",
    "for i in range(len(tweets)):\n",
    "    test_documents.append(word_tokenize(tweets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@', 'AmericanAir', 'In', 'car', 'gng', 'to', 'DFW', '.', 'Pulled', 'over', '1hr', 'ago', '-', 'very', 'icy', 'roads', '.', 'On-hold', 'with', 'AA', 'since', '1hr', '.', 'Ca', \"n't\", 'reach', 'arpt', 'for', 'AA2450', '.', 'Wat', '2', 'do', '?']\n"
     ]
    }
   ],
   "source": [
    "print(test_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents = [clean_tweet(tweet) for tweet in test_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['americanair', 'car', 'gng', 'dfw', 'pulled', '1hr', 'ago', 'icy', 'road', 'on-hold', 'aa', 'since', '1hr', 'ca', \"n't\", 'reach', 'arpt', 'aa2450', 'wat', '2']\n"
     ]
    }
   ],
   "source": [
    "print(test_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet_documents = [\" \".join(tweet) for tweet in test_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "americanair car gng dfw pulled 1hr ago icy road on-hold aa since 1hr ca n't reach arpt aa2450 wat 2\n"
     ]
    }
   ],
   "source": [
    "print(test_tweet_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = TfidfVectorizer(max_features=5000, max_df=0.8, min_df=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = count_vect.fit_transform(tweet_documents)\n",
    "y_train = sentiments\n",
    "\n",
    "x_test=count_vect.transform(test_tweet_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '10',\n",
       " '100',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '1hr',\n",
       " '1k',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2015',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '2hrs',\n",
       " '2nd',\n",
       " '30',\n",
       " '35',\n",
       " '36',\n",
       " '3rd',\n",
       " '40',\n",
       " '400',\n",
       " '45',\n",
       " '50',\n",
       " '500',\n",
       " '60',\n",
       " '70',\n",
       " '700',\n",
       " '728',\n",
       " '75',\n",
       " '800',\n",
       " '90',\n",
       " 'aa',\n",
       " 'able',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'access',\n",
       " 'accommodate',\n",
       " 'account',\n",
       " 'act',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'advantage',\n",
       " 'advise',\n",
       " 'advisory',\n",
       " 'afternoon',\n",
       " 'age',\n",
       " 'agent',\n",
       " 'ago',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'air',\n",
       " 'aircraft',\n",
       " 'airline',\n",
       " 'airlines',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airway',\n",
       " 'airways',\n",
       " 'alert',\n",
       " 'all',\n",
       " 'allow',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alternate',\n",
       " 'although',\n",
       " 'always',\n",
       " 'amaze',\n",
       " 'amazing',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanair',\n",
       " 'americanairlines',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'angry',\n",
       " 'announce',\n",
       " 'announcement',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apologize',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appease',\n",
       " 'apply',\n",
       " 'appreciate',\n",
       " 'april',\n",
       " 'area',\n",
       " 'around',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrives',\n",
       " 'asap',\n",
       " 'ask',\n",
       " 'assign',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'atl',\n",
       " 'atlanta',\n",
       " 'attempt',\n",
       " 'attendant',\n",
       " 'attitude',\n",
       " 'aus',\n",
       " 'austin',\n",
       " 'auto',\n",
       " 'automate',\n",
       " 'automatically',\n",
       " 'avail',\n",
       " 'available',\n",
       " 'avgeek',\n",
       " 'avoid',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'badcustomerservice',\n",
       " 'badservice',\n",
       " 'bag',\n",
       " 'baggage',\n",
       " 'bank',\n",
       " 'base',\n",
       " 'bathroom',\n",
       " 'bc',\n",
       " 'bday',\n",
       " 'bdl',\n",
       " 'beautiful',\n",
       " 'become',\n",
       " 'begin',\n",
       " 'behind',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'beyond',\n",
       " 'big',\n",
       " 'bin',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'blame',\n",
       " 'blue',\n",
       " 'bna',\n",
       " 'board',\n",
       " 'boarding',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'booking',\n",
       " 'bos',\n",
       " 'boston',\n",
       " 'bother',\n",
       " 'bought',\n",
       " 'brand',\n",
       " 'break',\n",
       " 'bring',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'bs',\n",
       " 'btw',\n",
       " 'buf',\n",
       " 'bumped',\n",
       " 'bus',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'buy',\n",
       " 'bwi',\n",
       " 'ca',\n",
       " 'cab',\n",
       " 'cabin',\n",
       " 'call',\n",
       " 'callback',\n",
       " 'called',\n",
       " 'can',\n",
       " 'cancelled',\n",
       " 'cant',\n",
       " 'captain',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'carousel',\n",
       " 'carrier',\n",
       " 'carry',\n",
       " 'case',\n",
       " 'catch',\n",
       " 'catering',\n",
       " 'cause',\n",
       " 'cc',\n",
       " 'center',\n",
       " 'ceo',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charlotte',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'checkin',\n",
       " 'chicago',\n",
       " 'child',\n",
       " 'choice',\n",
       " 'choose',\n",
       " 'city',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'client',\n",
       " 'close',\n",
       " 'clothes',\n",
       " 'clt',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'cmh',\n",
       " 'co',\n",
       " 'coat',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'cold',\n",
       " 'columbus',\n",
       " 'com',\n",
       " 'come',\n",
       " 'commercial',\n",
       " 'communication',\n",
       " 'companion',\n",
       " 'company',\n",
       " 'compensate',\n",
       " 'compensation',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'computer',\n",
       " 'concern',\n",
       " 'condition',\n",
       " 'conf',\n",
       " 'confirm',\n",
       " 'confirmation',\n",
       " 'confuse',\n",
       " 'congrats',\n",
       " 'connect',\n",
       " 'connection',\n",
       " 'consider',\n",
       " 'contact',\n",
       " 'continue',\n",
       " 'control',\n",
       " 'cool',\n",
       " 'corporate',\n",
       " 'correct',\n",
       " 'cost',\n",
       " 'could',\n",
       " 'count',\n",
       " 'counter',\n",
       " 'counting',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'courtesy',\n",
       " 'cover',\n",
       " 'crappy',\n",
       " 'crazy',\n",
       " 'create',\n",
       " 'credit',\n",
       " 'crew',\n",
       " 'cross',\n",
       " 'cry',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'cust',\n",
       " 'customer',\n",
       " 'customerservice',\n",
       " 'cut',\n",
       " 'dad',\n",
       " 'daily',\n",
       " 'dal',\n",
       " 'dallas',\n",
       " 'damage',\n",
       " 'damn',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'day',\n",
       " 'dc',\n",
       " 'dca',\n",
       " 'de',\n",
       " 'deal',\n",
       " 'death',\n",
       " 'decide',\n",
       " 'definitely',\n",
       " 'degree',\n",
       " 'delay',\n",
       " 'delayed',\n",
       " 'delays',\n",
       " 'deliver',\n",
       " 'delivery',\n",
       " 'delta',\n",
       " 'den',\n",
       " 'denver',\n",
       " 'deny',\n",
       " 'depart',\n",
       " 'department',\n",
       " 'departure',\n",
       " 'deplane',\n",
       " 'dept',\n",
       " 'deserves',\n",
       " 'desk',\n",
       " 'despite',\n",
       " 'destination',\n",
       " 'destinationdragons',\n",
       " 'detail',\n",
       " 'dfw',\n",
       " 'dfwairport',\n",
       " 'die',\n",
       " 'diego',\n",
       " 'diff',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'direct',\n",
       " 'disappoint',\n",
       " 'disappointed',\n",
       " 'disaster',\n",
       " 'disconnect',\n",
       " 'discount',\n",
       " 'disgust',\n",
       " 'divert',\n",
       " 'dividend',\n",
       " 'dm',\n",
       " 'do',\n",
       " 'dog',\n",
       " 'dollar',\n",
       " 'domestic',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'door',\n",
       " 'double',\n",
       " 'dragon',\n",
       " 'dream',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'drop',\n",
       " 'due',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'earn',\n",
       " 'east',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'economy',\n",
       " 'effort',\n",
       " 'either',\n",
       " 'else',\n",
       " 'email',\n",
       " 'emergency',\n",
       " 'employee',\n",
       " 'empty',\n",
       " 'end',\n",
       " 'engine',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'entertainment',\n",
       " 'entire',\n",
       " 'equipment',\n",
       " 'error',\n",
       " 'especially',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'event',\n",
       " 'eventually',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'ewr',\n",
       " 'exactly',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'excite',\n",
       " 'excuse',\n",
       " 'exit',\n",
       " 'expect',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'expire',\n",
       " 'explain',\n",
       " 'explanation',\n",
       " 'extend',\n",
       " 'extra',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'fail',\n",
       " 'failure',\n",
       " 'fair',\n",
       " 'fall',\n",
       " 'family',\n",
       " 'fan',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fare',\n",
       " 'fast',\n",
       " 'faster',\n",
       " 'fault',\n",
       " 'favorite',\n",
       " 'feature',\n",
       " 'feb',\n",
       " 'february',\n",
       " 'fee',\n",
       " 'feedback',\n",
       " 'feel',\n",
       " 'fight',\n",
       " 'figure',\n",
       " 'file',\n",
       " 'fill',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'first',\n",
       " 'fit',\n",
       " 'five',\n",
       " 'fix',\n",
       " 'fl',\n",
       " 'fleek',\n",
       " 'fleet',\n",
       " 'flew',\n",
       " 'flight',\n",
       " 'flightd',\n",
       " 'flighted',\n",
       " 'flighting',\n",
       " 'flightlation',\n",
       " 'flightlations',\n",
       " 'flightled',\n",
       " 'flightling',\n",
       " 'flightr',\n",
       " 'flights',\n",
       " 'fll',\n",
       " 'floor',\n",
       " 'florida',\n",
       " 'flown',\n",
       " 'flt',\n",
       " 'fly',\n",
       " 'flyer',\n",
       " 'flyfi',\n",
       " 'flying',\n",
       " 'folk',\n",
       " 'follow',\n",
       " 'food',\n",
       " 'foot',\n",
       " 'force',\n",
       " 'forever',\n",
       " 'forget',\n",
       " 'forgot',\n",
       " 'form',\n",
       " 'fort',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'four',\n",
       " 'free',\n",
       " 'freeze',\n",
       " 'frequent',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'front',\n",
       " 'frozen',\n",
       " 'frustrate',\n",
       " 'frustration',\n",
       " 'fuck',\n",
       " 'fuel',\n",
       " 'full',\n",
       " 'fun',\n",
       " 'funeral',\n",
       " 'funny',\n",
       " 'future',\n",
       " 'fyi',\n",
       " 'game',\n",
       " 'gate',\n",
       " 'get',\n",
       " 'give',\n",
       " 'glad',\n",
       " 'global',\n",
       " 'go',\n",
       " 'god',\n",
       " 'going',\n",
       " 'gold',\n",
       " 'gon',\n",
       " 'good',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'great',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'gt',\n",
       " 'guess',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'haha',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'handle',\n",
       " 'hang',\n",
       " 'happen',\n",
       " 'happens',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'hate',\n",
       " 'hawaii',\n",
       " 'head',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'hearing',\n",
       " 'held',\n",
       " 'hell',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'high',\n",
       " 'hire',\n",
       " 'hit',\n",
       " 'hold',\n",
       " 'holder',\n",
       " 'home',\n",
       " 'honest',\n",
       " 'honor',\n",
       " 'hop',\n",
       " 'hope',\n",
       " 'hopefully',\n",
       " 'hoping',\n",
       " 'horrible',\n",
       " 'hot',\n",
       " 'hotel',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'houston',\n",
       " 'however',\n",
       " 'hr',\n",
       " 'http',\n",
       " 'huge',\n",
       " 'human',\n",
       " 'hundred',\n",
       " 'hung',\n",
       " 'husband',\n",
       " 'iad',\n",
       " 'iah',\n",
       " 'ice',\n",
       " 'id',\n",
       " 'idea',\n",
       " 'ignore',\n",
       " 'im',\n",
       " 'imagine',\n",
       " 'imaginedragons',\n",
       " 'important',\n",
       " 'impossible',\n",
       " 'impressed',\n",
       " 'in',\n",
       " 'include',\n",
       " 'incompetence',\n",
       " 'incompetent',\n",
       " 'inconvenience',\n",
       " 'incredibly',\n",
       " 'infant',\n",
       " 'inflight',\n",
       " 'info',\n",
       " 'inform',\n",
       " 'information',\n",
       " 'inside',\n",
       " 'instead',\n",
       " 'international',\n",
       " 'internet',\n",
       " 'intl',\n",
       " 'iphone',\n",
       " 'issue',\n",
       " 'item',\n",
       " 'itinerary',\n",
       " 'jblu',\n",
       " 'jet',\n",
       " 'jetblue',\n",
       " 'jetway',\n",
       " 'jfk',\n",
       " 'job',\n",
       " 'joke',\n",
       " 'juan',\n",
       " 'keep',\n",
       " 'kept',\n",
       " 'kid',\n",
       " 'kill',\n",
       " 'kind',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'kudos',\n",
       " 'la',\n",
       " 'lack',\n",
       " 'lady',\n",
       " 'land',\n",
       " 'large',\n",
       " 'las',\n",
       " 'last',\n",
       " 'late',\n",
       " 'lax',\n",
       " 'layover',\n",
       " 'lead',\n",
       " 'learn',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'left',\n",
       " 'leg',\n",
       " 'legroom',\n",
       " 'less',\n",
       " 'let',\n",
       " 'letter',\n",
       " 'level',\n",
       " 'lga',\n",
       " 'lie',\n",
       " 'life',\n",
       " 'like',\n",
       " 'likely',\n",
       " 'line',\n",
       " 'link',\n",
       " 'list',\n",
       " 'listen',\n",
       " 'literally',\n",
       " 'little',\n",
       " 'live',\n",
       " 'll',\n",
       " 'load',\n",
       " 'locate',\n",
       " 'location',\n",
       " 'log',\n",
       " 'logan',\n",
       " 'lol',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'lose',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'lots',\n",
       " 'lounge',\n",
       " 'love',\n",
       " 'lovely',\n",
       " 'low',\n",
       " 'loyal',\n",
       " 'lt',\n",
       " 'luck',\n",
       " 'luggage',\n",
       " 'luv',\n",
       " 'mad',\n",
       " 'made',\n",
       " 'mail',\n",
       " 'maintenance',\n",
       " 'major',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'man',\n",
       " 'manage',\n",
       " 'many',\n",
       " 'march',\n",
       " 'mark',\n",
       " 'match',\n",
       " 'matter',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'mco',\n",
       " 'mdw',\n",
       " 'meal',\n",
       " 'mean',\n",
       " 'mechanical',\n",
       " 'medium',\n",
       " 'meeting',\n",
       " 'member',\n",
       " 'mention',\n",
       " 'merge',\n",
       " 'merger',\n",
       " 'mess',\n",
       " 'message',\n",
       " 'met',\n",
       " 'mexico',\n",
       " 'mia',\n",
       " 'miami',\n",
       " 'middle',\n",
       " 'midnight',\n",
       " 'might',\n",
       " 'mile',\n",
       " 'mileage',\n",
       " 'mileageplus',\n",
       " 'miles',\n",
       " 'military',\n",
       " 'min',\n",
       " 'mind',\n",
       " 'mine',\n",
       " 'minor',\n",
       " 'mint',\n",
       " 'minute',\n",
       " 'miss',\n",
       " 'missed',\n",
       " 'missing',\n",
       " 'mistake',\n",
       " 'mobile',\n",
       " 'mom',\n",
       " 'mon',\n",
       " 'monday',\n",
       " 'money',\n",
       " 'month',\n",
       " 'morning',\n",
       " 'move',\n",
       " 'movie',\n",
       " 'msg',\n",
       " 'much',\n",
       " 'multiple',\n",
       " 'music',\n",
       " 'must',\n",
       " 'na',\n",
       " 'name',\n",
       " 'nashville',\n",
       " 'nc',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'need',\n",
       " 'never',\n",
       " 'neveragain',\n",
       " 'new',\n",
       " 'newark',\n",
       " 'news',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'nightmare',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'none',\n",
       " 'nonstop',\n",
       " 'nope',\n",
       " 'not',\n",
       " 'note',\n",
       " 'nothing',\n",
       " 'notice',\n",
       " 'notification',\n",
       " 'notify',\n",
       " 'number',\n",
       " 'ny',\n",
       " 'nyc',\n",
       " 'obviously',\n",
       " 'offer',\n",
       " 'offering',\n",
       " 'office',\n",
       " 'officially',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'omg',\n",
       " 'on',\n",
       " 'onboard',\n",
       " 'one',\n",
       " 'online',\n",
       " 'onto',\n",
       " 'open',\n",
       " 'opportunity',\n",
       " 'option',\n",
       " 'ord',\n",
       " 'order',\n",
       " 'original',\n",
       " 'originally',\n",
       " 'orlando',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'outstanding',\n",
       " 'overbooked',\n",
       " 'overhead',\n",
       " 'overnight',\n",
       " 'page',\n",
       " 'paid',\n",
       " 'parent',\n",
       " 'part',\n",
       " 'partner',\n",
       " 'party',\n",
       " 'pas',\n",
       " 'pass',\n",
       " 'passbook',\n",
       " 'passenger',\n",
       " 'past',\n",
       " 'pathetic',\n",
       " 'patience',\n",
       " 'pay',\n",
       " 'pbi',\n",
       " 'pdx',\n",
       " 'people',\n",
       " 'per',\n",
       " 'perfect',\n",
       " 'perhaps',\n",
       " 'person',\n",
       " 'personal',\n",
       " 'philadelphia',\n",
       " 'philly',\n",
       " 'phl',\n",
       " 'phlairport',\n",
       " 'phoenix',\n",
       " 'phone',\n",
       " 'photo',\n",
       " 'phx',\n",
       " 'pic',\n",
       " 'pick',\n",
       " 'picked',\n",
       " 'picture',\n",
       " 'pilot',\n",
       " 'pit',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'plane',\n",
       " 'planning',\n",
       " 'platinum',\n",
       " 'play',\n",
       " 'pleasant',\n",
       " 'please',\n",
       " 'plenty',\n",
       " 'pls',\n",
       " 'plus',\n",
       " 'plz',\n",
       " 'pm',\n",
       " 'point',\n",
       " 'policy',\n",
       " 'poor',\n",
       " 'possible',\n",
       " 'post',\n",
       " 'power',\n",
       " 'ppl',\n",
       " 'pr',\n",
       " 'pre',\n",
       " 'prefer',\n",
       " 'premier',\n",
       " 'pretty',\n",
       " 'previous',\n",
       " 'price',\n",
       " 'prior',\n",
       " 'priority',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'process',\n",
       " 'professional',\n",
       " 'profit',\n",
       " 'program',\n",
       " 'promise',\n",
       " 'promo',\n",
       " 'prompt',\n",
       " 'provide',\n",
       " 'public',\n",
       " 'pull',\n",
       " 'purchase',\n",
       " 'push',\n",
       " 'put',\n",
       " 'quality',\n",
       " 'question',\n",
       " 'quick',\n",
       " 'quickly',\n",
       " 'raise',\n",
       " 'rate',\n",
       " 'rather',\n",
       " 'rdu',\n",
       " 're',\n",
       " 'reach',\n",
       " 'read',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'realize',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'rebook',\n",
       " 'rebooked',\n",
       " 'receipt',\n",
       " 'receive',\n",
       " 'record',\n",
       " 'red',\n",
       " 'redeem',\n",
       " 'reflight',\n",
       " 'refund',\n",
       " 'refuse',\n",
       " 'regard',\n",
       " 'reimburse',\n",
       " 'reimbursement',\n",
       " 'relate',\n",
       " 'relation',\n",
       " 'remember',\n",
       " 'remove',\n",
       " 'rental',\n",
       " 'rep',\n",
       " 'reply',\n",
       " 'report',\n",
       " 'representative',\n",
       " 'request',\n",
       " 'require',\n",
       " 'reschedule',\n",
       " 'reservation',\n",
       " 'reserve',\n",
       " 'resolution',\n",
       " 'resolve',\n",
       " 'respect',\n",
       " 'respond',\n",
       " 'response',\n",
       " 'result',\n",
       " 'retrieve',\n",
       " 'return',\n",
       " 'reward',\n",
       " 'ride',\n",
       " 'ridiculous',\n",
       " 'right',\n",
       " 'rock',\n",
       " 'room',\n",
       " 'round',\n",
       " 'route',\n",
       " 'row',\n",
       " 'rt',\n",
       " 'rude',\n",
       " 'ruin',\n",
       " 'rule',\n",
       " 'run',\n",
       " 'runway',\n",
       " 'sad',\n",
       " 'safe',\n",
       " 'safely',\n",
       " 'safety',\n",
       " 'sale',\n",
       " 'san',\n",
       " 'sat',\n",
       " 'saturday',\n",
       " 'save',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'schedule',\n",
       " 'screen',\n",
       " 'screw',\n",
       " 'sea',\n",
       " 'seat',\n",
       " 'seattle',\n",
       " 'second',\n",
       " 'security',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seems',\n",
       " 'select',\n",
       " 'sell',\n",
       " 'send',\n",
       " 'sense',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'seriously',\n",
       " 'serve',\n",
       " 'service',\n",
       " 'set',\n",
       " 'several',\n",
       " 'sf',\n",
       " 'sfo',\n",
       " 'shame',\n",
       " 'share',\n",
       " 'shit',\n",
       " 'short',\n",
       " 'shout',\n",
       " 'show',\n",
       " 'shuttle',\n",
       " 'sick',\n",
       " 'side',\n",
       " ...]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piyush Pravin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'negative', 'negative', ..., 'negative', 'negative',\n",
       "       'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"prediction.csv\", y_test, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
